---
layout:     post
title:      大模型笔记（LLM）
subtitle:   大语言模型基础
date:       2024-9-1
author:     月月鸟
header-img: img/LLM.jpg
catalog: true
tags:
    - LLM
---

# 1. 语言模型

## 1.1. 定义
语言模型（LM）的经典定义是描述令牌序列的概率分布。假设存在一个令牌集的词汇表 \( V \)，语言模型 \( p \) 为每个令牌序列 \( x_1, x_2, \ldots, x_L \in V \) 分配一个概率值，范围在0到1之间：

\[
p(x_1, x_2, \ldots, x_L)
\]

这个概率表明了一个令牌序列的“好坏”。例如，假设词汇表为 \{ate, ball, cheese, mouse, the\}，语言模型可能会给出以下示例概率：

\[
p(\text{the, mouse, ate, the, cheese}) = 0.02,
\]

\[
p(\text{the, cheese, ate, the, mouse}) = 0.01,
\]

\[
p(\text{mouse, the, the, cheese, ate}) = 0.0001.
\]

尽管从数学上看，语言模型的概念简单而优雅，但这种简单性具有误导性。为了给所有序列赋予有意义的概率，语言模型需要具备高度的语言理解和世界知识。

例如，语言模型应该给予 "𝗆𝗈𝗎𝗌𝖾 𝗍𝗁𝖾 𝗍𝗁𝖾 𝖼𝗁𝖾𝖾𝗌𝖾 𝖺𝗍𝖾" 一个极低的概率，因为这在语法上是不正确的（反映了句法知识）。同时，语言模型应给予 "𝗍𝗁𝖾 𝗆𝗈𝗎𝗌𝖾 𝖺𝗍𝖾 𝗍𝗁𝖾 𝖼𝗁𝖾𝖾𝗌𝖾" 比 "𝗍𝗁𝖾 𝖼𝗁𝖾𝖾𝗌𝖾 𝖺𝗍𝖾 𝗍𝗁𝖾 𝗆𝗈𝗎𝗌𝖾" 更高的概率。尽管这两个句子在结构上是相似的，但在语义上却有差异，语言模型必须具备丰富的语言能力和世界知识，以准确评估序列的概率。

此外，语言模型也可用于生成任务。根据其定义，语言模型 \( p \) 接受一个序列并返回其概率以评估好坏。我们还可以根据语言模型生成一个序列。最基本的方法是从语言模型 \( p \) 中以概率 \( p(x_1:L) \) 进行采样，表示为：

\[
x_{1:L} \sim p.
\]

如何高效地实现这一点依赖于语言模型 \( p \) 的具体形式。实际上，我们通常不直接从语言模型中采样，原因不仅在于真实语言模型的局限性，还因为我们有时更希望获得接近“最佳”序列的结果，而非“平均”序列。


## 1.2. 自回归语言模型(Autoregressive language models)

自回归语言模型通过使用概率的链式法则来描述令牌序列 \( x_{1:L} \) 的联合分布 \( p(x_{1:L}) \)：

\[
p(x_{1:L}) = p(x_1) \cdot p(x_2 \mid x_1) \cdot p(x_3 \mid x_1, x_2) \cdots p(x_L \mid x_{1:L-1}) = \prod_{i=1}^L p(x_i \mid x_{1:i-1}).
\]

举个例子，考虑一个简单的文本序列：

\[
p(\text{the}, \text{mouse}, \text{ate}, \text{the}, \text{cheese}) = p(\text{the}) \cdot p(\text{mouse} \mid \text{the}) \cdot p(\text{ate} \mid \text{the}, \text{mouse}) \cdot p(\text{the} \mid \text{the}, \text{mouse}, \text{ate}) \cdot p(\text{cheese} \mid \text{the}, \text{mouse}, \text{ate}, \text{the}).
\]

这里，\( p(x_i \mid x_{1:i-1}) \) 表示在已生成的标记  $x_{1:i-1}$  的基础上，预测下一个标记 \( x_i \) 的条件概率。任何联合概率分布都可以这样表示，但自回归语言模型的独特之处在于它**能够通过前馈神经网络等高效计算每个条件概率分布** \( p(x_i \mid x_{1:i-1}) \)。在生成整个序列 \( x_{1:L} \) 时，我们逐步生成每一个标记，这些标记基于之前生成的标记计算得出。

对于每个位置 \( i = 1, \ldots, L \)：

\[
x_i \sim p(x_i \mid x_{1:i-1})^{1/T},
\]

其中 \( T \) 是一个温度参数，用于控制生成过程中的随机性：

- **\( T = 0 \)**：在每个位置确定性地选择最可能的标记 \( x_i \)。
- **\( T = 1 \)**：从原始语言模型进行“正常”采样。
- **\( T = \infty \)**：从整个词汇表均匀地随机选择标记。

当将概率提升至 \( 1/T \) 次方时，得到的概率分布可能不再和为1。为了解决这个问题，我们需要对分布进行重新标准化，从而得到标准化版本：

\[
p_T(x_i \mid x_{1:i-1}) \propto p(x_i \mid x_{1:i-1})^{1/T}.
\]

这就是**退火条件概率分布**的概念。例如，假设某些初始概率如下：

- \( p(\text{cheese}) = 0.4 \)，\( p(\text{mouse}) = 0.6 \)
- 当 \( T = 0.5 \) 时，\( p_T(\text{cheese}) = 0.31 \)，\( p_T(\text{mouse}) = 0.69 \)
- 当 \( T = 0.2 \) 时，\( p_T(\text{cheese}) = 0.12 \)，\( p_T(\text{mouse}) = 0.88 \)
- 当 \( T = 0 \) 时，\( p_T(\text{cheese}) = 0 \)，\( p_T(\text{mouse}) = 1 \)

温度参数的引入会在每一步的条件概率分布中调整概率的平滑度。较高的 \( T \) 值使得分布更均匀，生成的文本更加多样；而较低的 \( T \) 值则使模型更倾向于生成高概率的标记。

需要注意的是，对每一步的条件概率分布应用温度参数并进行迭代采样，与直接从整个长度为 \( L \) 的"退火"分布中一次性采样是不同的（除非 \( T = 1 \)）。当 \( T \neq 1 \) 时，这两种方法可能会产生不同的结果。

**退火**一词源于冶金学，金属在冷却过程中会改变其物理特性。在这里，退火比喻为调整概率分布的过程。**"退火"分布是通过将原始概率分布中的每个元素取 \( 1/T \) 次方，然后进行重新标准化得到的新的分布**。当 \( T \neq 1 \) 时，这个过程改变了原始概率分布，因此从"退火"分布中采样的结果可能与逐步采样的结果不同。

在非自回归条件生成中，我们可以指定一个前缀序列 \( x_{1:i} \)（即提示），并从中采样其余部分 \( x_{i+1:L} \)（称为补全）。例如，生成 \( T = 0 \) 的结果可能是：

\[
\text{the, mouse, ate} \underbrace{\rightarrow}_{T=0} \text{the, cheese}.
\]

而将温度改为 \( T = 1 \) 时，可能会产生更丰富的结果，例如“its house”或“my homework”。

这种条件生成的能力使得语言模型能够通过简单的调整提示，完成多种任务。

---

# 2. 大模型的历史

大模型（尤其是语言模型）的发展历程，是人工智能（AI）领域从规则驱动到数据驱动，再到深度学习与预训练模型逐步成熟的过程。以下是语言模型和大模型发展的关键阶段和重要里程碑：

## 1. 早期阶段（20世纪50-90年代）
- **1950年代 - 图灵测试**：1950年，艾伦·图灵提出了图灵测试，认为如果一台机器能够通过对话让人无法区分其与人类，那么这台机器就具备“智能”。这为自然语言处理（NLP）研究奠定了早期的理论基础。
- **规则驱动的方法**：最初的NLP研究基于规则和专家系统，通过预定义语法和词汇来理解和生成语言。这些系统虽然适合一些简单的任务，但缺乏灵活性，无法处理复杂的语言现象。

## 2. 统计语言模型阶段（1990年代-2010年代初）
- **N-gram模型**：统计语言模型开始流行，特别是N-gram模型，它通过统计固定窗口内词汇的共现概率来预测下一个词。这种方法虽然简单，但在面对更长依赖关系时，效果有限。
- **HMM和CRF**：在词性标注和命名实体识别等任务中，隐马尔可夫模型（HMM）和条件随机场（CRF）取得了进展。这些模型利用了词汇序列中的依赖关系，但对于长距离依赖的语言现象处理仍然有局限。

## 3. 深度学习阶段（2010年代中期）
- **Word2Vec（2013）**：Mikolov等人提出了Word2Vec模型，通过神经网络学习词的向量表示（词嵌入），为NLP带来了革命性的变化。Word2Vec能够捕捉词语之间的语义关系，并且推动了之后深度学习在NLP中的应用。
- **RNN和LSTM（2014）**：循环神经网络（RNN）和长短期记忆网络（LSTM）在自然语言建模中表现出色，解决了部分长距离依赖的问题。LSTM特别擅长捕捉序列数据中的依赖关系，在文本生成、机器翻译等任务中取得了较好的效果。
- **Seq2Seq模型（2014）**：Sutskever等人提出的Seq2Seq模型及其后续的注意力机制（Attention）极大提升了机器翻译的性能，为深度学习在NLP中的应用奠定了基础。

## 4. Transformer和预训练模型阶段（2017年-至今）
- **Transformer（2017）**：Vaswani等人提出了Transformer架构，彻底改变了NLP的研究方向。Transformer利用自注意力机制（Self-Attention）处理序列数据，使得模型在并行计算、长距离依赖处理上更加高效。它不再需要RNN的循环结构，极大地提升了训练速度和模型性能。
- **BERT（2018）**：Google发布的BERT（Bidirectional Encoder Representations from Transformers）通过双向编码器从大规模语料中预训练，并通过微调（Fine-tuning）适应具体任务，显著提高了自然语言理解的效果。BERT的发布标志着预训练模型在NLP领域的普及。
- **GPT系列（2018-2023）**：OpenAI推出了GPT（Generative Pretrained Transformer）系列模型，包括GPT、GPT-2、GPT-3和GPT-4。这些模型是典型的自回归语言模型，擅长生成类任务。GPT-3的参数量达到1750亿，是当时最大的公开语言模型，展示了模型参数规模与性能提升之间的关系。
- **T5和其他多任务模型（2019）**：Google发布的T5（Text-To-Text Transfer Transformer）通过将所有NLP任务转化为统一的文本生成问题，展示了模型在处理多种任务上的通用性。T5的多任务学习思路对之后的多模态大模型产生了深远影响。
- **多模态模型（2020年代）**：随着模型能力的提升，研究者开始探索多模态模型的发展，这类模型不仅能处理文本，还能处理图像、音频等不同模态的数据。OpenAI的CLIP和DALL-E是多模态模型的代表，它们结合了视觉与语言的理解和生成能力。

## 5. 参数规模与模型性能的增长（2020年及之后）
- **大模型的参数化趋势**：2020年代以来，随着硬件计算能力的提升和分布式训练技术的发展，越来越多的研究团队开发出参数量庞大的语言模型。这些大模型在语言理解、生成、问答、翻译等任务上表现卓越。
- **GPT-4和更大规模的模型**：GPT-4进一步提高了语言生成和理解的能力，支持更复杂的推理和多轮对话。其他公司也推出了类似的大模型，如Google的PaLM系列和Anthropic的Claude等，进一步推动了语言模型在科研和应用领域的进步。
- **开源大模型的崛起**：随着Meta（Facebook）等公司推出的开源大模型，如LLaMA等，开源社区的参与度显著提升。这使得更多研究者和开发者能够在自有数据上微调和定制模型，推动了模型的可定制化和领域适应性。

## 6. 模型能力与社会影响的探索（2020年代中期-至今）
- **社会影响与监管讨论**：随着大模型应用的普及，其社会影响和风险也逐渐引起关注。包括模型的偏见、数据隐私、生成内容的真实性等问题都成为了讨论的焦点。各国和机构逐渐开始讨论对大模型开发和应用的监管框架。
- **模型能力的研究与测评**：研究者们致力于探讨大模型的推理能力、世界知识、以及在多语言和多领域上的适应性。与此同时，模型在创造性写作、程序生成、医疗诊断等专业领域的应用前景也在逐步探索。

---
